{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c54141",
   "metadata": {},
   "source": [
    "## Spam Email Classifier with KNN using TF-IDF scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17102e",
   "metadata": {},
   "source": [
    "1.   Assignment must be implemented in Python 3 only.\n",
    "2.   You are allowed to use libraries for data preprocessing (numpy, pandas, nltk etc) and for evaluation metrics, data visualization (matplotlib etc.).\n",
    "3.   You will be evaluated not just on the overall performance of the model and also on the experimentation with hyper parameters, data prepossessing techniques etc.\n",
    "4.   The report file must be a well documented jupyter notebook, explaining the experiments you have performed, evaluation metrics and corresponding code. The code must run and be able to reproduce the accuracies, figures/graphs etc.\n",
    "5.   For all the questions, you must create a train-validation data split and test the hyperparameter tuning on the validation set. Your jupyter notebook must reflect the same.\n",
    "6.   Strict plagiarism checking will be done. An F will be awarded for plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d34a310",
   "metadata": {},
   "source": [
    "**Task: Given an email, classify it as spam or ham**\n",
    "\n",
    "Given input text file (\"emails.txt\") containing 5572 email messages, with each row having its corresponding label (spam/ham) attached to it.\n",
    "\n",
    "This task also requires basic pre-processing of text (like removing stopwords, stemming/lemmatizing, replacing email_address with 'email-tag', etc..).\n",
    "\n",
    "You are required to find the tf-idf scores for the given data and use them to perform KNN using Cosine Similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c87696",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5a1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "import re, math\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef4dff",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f178f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emails.txt', 'r') as file:\n",
    "    crudeData = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ef5ba",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1733d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verdict = [0]\n",
    "score = dict()\n",
    "modValue = dict()\n",
    "stemmedWords = dict()\n",
    "id = 0\n",
    "for line in crudeData:\n",
    "    id += 1\n",
    "    line = line.casefold()\n",
    "    splitt = re.split(r'[^A-Za-z0-9]+', line)\n",
    "    if len(splitt) < 2:\n",
    "        print(id, splitt)\n",
    "        continue\n",
    "    verdict.append(0)\n",
    "    if splitt[0] == \"spam\":\n",
    "        verdict[id] = 1\n",
    "    else:\n",
    "        verdict[id] = 0\n",
    "\n",
    "    totalCount = len(splitt) - 1\n",
    "    counts = dict()\n",
    "    for i in splitt[1:-1]:\n",
    "        if i == '':\n",
    "            continue\n",
    "        if i not in stopwords_set:\n",
    "            if i not in stemmedWords:\n",
    "                stemmedWords[i] = stemmer.stem(i)\n",
    "            if stemmedWords[i] not in counts:\n",
    "                counts[stemmedWords[i]] = 0\n",
    "            counts[stemmedWords[i]] += 1\n",
    "    \n",
    "    score[id] = dict()\n",
    "    modValue[id] = 0\n",
    "    for word in counts:\n",
    "        score[id][word] = math.log(1 + counts[word]) * math.log(totalCount/counts[word])\n",
    "        modValue[id] += score[id][word]**2\n",
    "    modValue[id] = (modValue[id])**(0.5)\n",
    "\n",
    "def cosineSimilarity(a, b):\n",
    "    global modValue, score\n",
    "    similarity = 0\n",
    "    if modValue[a] * modValue[b] == 0 or a == b:\n",
    "        return 0\n",
    "    for word in score[a]:\n",
    "        if word in score[b]:\n",
    "            similarity += score[b][word]*score[a][word]\n",
    "    similarity /= (modValue[a]*modValue[b])\n",
    "    return similarity\n",
    "dist = [[] for i in range(0, id+1)]\n",
    "for i in range(1, id):\n",
    "    for j in range(1, id):\n",
    "        dist[i].append([cosineSimilarity(i, j), j])\n",
    "    dist[i].sort(reverse=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76767a7",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75e6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(id+1)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x[1:], verdict[1:], test_size = 0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6eb76b",
   "metadata": {},
   "source": [
    "### Train your KNN model (reuse previously iplemented model built from scratch) and test on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa74e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as skm\n",
    "\n",
    "'''find knn,\n",
    "iterate over a set of k and for each k,\n",
    "try different criteria to assign a verdict on spam or not spam\n",
    "\n",
    "based on the result from above, plot a graph to understand\n",
    "which parameters performed the best'''\n",
    "def KNNAlgorithm(k, dist, metrics):\n",
    "    global x_train, x_validation, y_train, y_validation\n",
    "\n",
    "    # go over training dataset and find the avg number of spams in k \n",
    "    # needed to specify spam\n",
    "    spamThreshold = 0\n",
    "    for x in range(len(x_train)):\n",
    "        if y_train[x] == 1:\n",
    "            temp = dist[x_train[x]][:k]\n",
    "            for i in temp:\n",
    "                spamThreshold += verdict[i[1]]\n",
    "    spamThreshold /= len(x_train)\n",
    "\n",
    "    y_out = []\n",
    "    for x in range(len(x_validation)):\n",
    "        temp = dist[x_validation[x]][:k]\n",
    "        count = 0\n",
    "        y_out.append(0)\n",
    "        for i in temp:\n",
    "            count += verdict[i[1]]\n",
    "        if count >= spamThreshold:\n",
    "            y_out[x] = 1\n",
    "        else:\n",
    "            y_out[x] = 0\n",
    "    \n",
    "    # print('Spam threshold =', spamThreshold, \"- for k =\", k, \"- with following results\") \n",
    "    # disp = skm.ConfusionMatrixDisplay(skm.confusion_matrix(y_validation, y_out))\n",
    "    # disp.plot()\n",
    "    ar = [\n",
    "        skm.confusion_matrix(y_validation, y_out).ravel(), \n",
    "        skm.accuracy_score(y_validation, y_out), \n",
    "        skm.recall_score(y_validation, y_out),\n",
    "        skm.f1_score(y_validation, y_out)\n",
    "        ]\n",
    "    metrics.append(ar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1da9c",
   "metadata": {},
   "source": [
    "Below, we implement KNN for cosine similarity distance measure for a varying k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a6b8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [1, 3, 5, 7,11, 17, 23, 28]\n",
    "\n",
    "'''\n",
    "metrics is a dictionary with distance methods as keys \n",
    "and each key corresponds to an array of values for different evaluation metrics\n",
    "\n",
    "each array of metrics is of form [confusion matrix, accuracy, recall, f1-score]\n",
    "'''\n",
    "metrics = dict()\n",
    "def applyAlgorithm(distanceMethod):\n",
    "    global metrics, k_list\n",
    "    metrics[distanceMethod] = []\n",
    "    for k in k_list:\n",
    "        KNNAlgorithm(k, dist, metrics[distanceMethod])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22baf6b2",
   "metadata": {},
   "source": [
    "***1. Experiment with different distance measures [Euclidean distance, Manhattan distance, Hamming Distance] and compare with the Cosine Similarity distance results.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68f1bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cosine': [[array([975,   1,  20, 119]), 0.9811659192825112, 0.8561151079136691, 0.918918918918919], [array([973,   3,   9, 130]), 0.989237668161435, 0.935251798561151, 0.9558823529411764], [array([962,  14,   6, 133]), 0.9820627802690582, 0.9568345323741008, 0.93006993006993], [array([951,  25,   5, 134]), 0.9730941704035875, 0.9640287769784173, 0.8993288590604027], [array([945,  31,   7, 132]), 0.9659192825112107, 0.9496402877697842, 0.8741721854304636], [array([922,  54,   5, 134]), 0.947085201793722, 0.9640287769784173, 0.8195718654434251], [array([940,  36,   7, 132]), 0.9614349775784753, 0.9496402877697842, 0.8599348534201955], [array([921,  55,   4, 135]), 0.947085201793722, 0.9712230215827338, 0.8206686930091185]]}\n"
     ]
    }
   ],
   "source": [
    "applyAlgorithm('cosine')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6f3b1",
   "metadata": {},
   "source": [
    "***2. Explain which distance measure works best and why? Explore the distance measures and weigh their pro and cons in different application settings.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae57a01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45a99c76",
   "metadata": {},
   "source": [
    "***3. Report Confusion matrix along with accuracy, recall, precision and F1-score in the form of a table***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9668814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4dde8d3",
   "metadata": {},
   "source": [
    "***4. Choose different K values (k=1,3,5,7,11,17,23,28) and experiment. Plot a graph showing R2 score vs k.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0fd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15000352",
   "metadata": {},
   "source": [
    "### Train and test Sklearn's KNN classifier model on your data (use metric which gave best results on your experimentation with built-from-scratch model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aab7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d22aa47",
   "metadata": {},
   "source": [
    "***Compare both the models result.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a5274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64987575",
   "metadata": {},
   "source": [
    "***What is the time complexity of training using KNN classifier?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770c106",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fad1f345",
   "metadata": {},
   "source": [
    "***What is the time complexity while testing? Is KNN a linear classifier or can it learn any boundary?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daaa324",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
